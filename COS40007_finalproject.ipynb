{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1o4fkfZ_HeB4ZXyEyLk-eNhGDc8f7rJxN",
      "authorship_tag": "ABX9TyMDTZAeB7247oqlD36u8JA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathanVuSwinburne/Structural-Defect-Detection-AI-for-Structural-Engineering/blob/remove-dockerise/COS40007_finalproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw-JJFegycJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9775a8f6-5d3d-41bc-aa55-60109ad71b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  drive.mount('/content/drive')\n",
        "  os.chdir('/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if we are using GPU or not...\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Bj6W1RtvzSni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8d5327-f2fb-4d8b-fa59-3755cb31be41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 24 05:02:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "-XzweGRQzViK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af36b63-632f-4850-d8f1-2395e499a519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EcBCHHxzZND",
        "outputId": "a231eff9-9f08-43bd-b65a-44db91bf58be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.143)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "from IPython.display import display, Image, clear_output\n",
        "clear_output()\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "!pip install roboflow"
      ],
      "metadata": {
        "id": "_9NFjmMEzbWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9a1630-59cc-4a79-baba-2746880c6073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.143 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Setup complete ✅ (12 CPUs, 83.5 GB RAM, 42.4/235.7 GB disk)\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.64)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Requirement already satisfied: pillow-heif>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"sGMMjyN0L8bBltD06Jzu\")\n",
        "project = rf.workspace(\"cos40007-workspace\").project(\"cos40007-final-project\")\n",
        "version = project.version(8)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GHOyE4OJz1LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65de2672-ebc4-4d5e-f7e4-5e4ec55b8ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in COS40007-Final-Project-8 to yolov8:: 100%|██████████| 608554/608554 [00:32<00:00, 18598.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to COS40007-Final-Project-8 in yolov8:: 100%|██████████| 6100/6100 [00:35<00:00, 170.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO Dataset Processor for Object Detection and Segmentation\n",
        "# This notebook splits a multi-class YOLO dataset into separate datasets for:\n",
        "# - Bounding box detection (Classes 0-1: Crack, Rust)\n",
        "# - Segmentation (Class 2: Tower Structure)\n",
        "\n",
        "# Install required packages\n",
        "!pip install opencv-python\n",
        "!pip install pyyaml\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import argparse\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define paths - Modify these depending on your dataset location\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8\"  # Default Colab working directory\n",
        "\n",
        "# Create paths for split datasets\n",
        "BBOX_DATASET = os.path.join(DATASET_ROOT, \"bbox_dataset\")\n",
        "SEG_DATASET = os.path.join(DATASET_ROOT, \"seg_dataset\")\n",
        "\n",
        "# Function to create directory structure\n",
        "def create_directory_structure():\n",
        "    \"\"\"Create the directory structure for both datasets\"\"\"\n",
        "    for dataset_path in [BBOX_DATASET, SEG_DATASET]:\n",
        "        for split in [\"train\", \"valid\", \"test\"]:\n",
        "            for subdir in [\"images\", \"labels\"]:\n",
        "                os.makedirs(os.path.join(dataset_path, split, subdir), exist_ok=True)\n",
        "    print(\"✅ Directory structure created\")\n",
        "\n",
        "# Function to split a label file into bbox and segmentation components\n",
        "def split_label_file(input_file, bbox_output_file, seg_output_file):\n",
        "    \"\"\"Split a YOLO label file into separate bbox and segmentation files\"\"\"\n",
        "    bbox_lines = []\n",
        "    seg_lines = []\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "\n",
        "            class_id = int(parts[0])\n",
        "\n",
        "            # Class 0 (Crack) and Class 1 (Rust) are bounding boxes\n",
        "            if class_id == 0 or class_id == 1:\n",
        "                bbox_lines.append(line)\n",
        "            # Class 2 (Tower Structure) is segmentation\n",
        "            elif class_id == 2:\n",
        "                # Adjust class_id to 0 for the segmentation dataset\n",
        "                new_line = \"0\" + line[1:]\n",
        "                seg_lines.append(new_line)\n",
        "\n",
        "    # Only write files if they have content\n",
        "    if bbox_lines:\n",
        "        with open(bbox_output_file, 'w') as f:\n",
        "            f.writelines(bbox_lines)\n",
        "\n",
        "    if seg_lines:\n",
        "        with open(seg_output_file, 'w') as f:\n",
        "            f.writelines(seg_lines)\n",
        "\n",
        "    return bool(bbox_lines), bool(seg_lines)\n",
        "\n",
        "# Function to process a dataset split\n",
        "def process_split(split):\n",
        "    \"\"\"Process a dataset split (train/valid/test)\"\"\"\n",
        "    labels_dir = os.path.join(DATASET_ROOT, split, \"labels\")\n",
        "    images_dir = os.path.join(DATASET_ROOT, split, \"images\")\n",
        "\n",
        "    bbox_labels_dir = os.path.join(BBOX_DATASET, split, \"labels\")\n",
        "    bbox_images_dir = os.path.join(BBOX_DATASET, split, \"images\")\n",
        "\n",
        "    seg_labels_dir = os.path.join(SEG_DATASET, split, \"labels\")\n",
        "    seg_images_dir = os.path.join(SEG_DATASET, split, \"images\")\n",
        "\n",
        "    print(f\"Processing {split} split...\")\n",
        "    print(f\"Source images: {images_dir}\")\n",
        "\n",
        "    # Check if source directories exist\n",
        "    if not os.path.exists(labels_dir):\n",
        "        print(f\"⚠️ Warning: Source labels directory {labels_dir} does not exist\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(images_dir):\n",
        "        print(f\"⚠️ Warning: Source images directory {images_dir} does not exist\")\n",
        "        return\n",
        "\n",
        "    # Process each label file in the split\n",
        "    processed_bbox = 0\n",
        "    processed_seg = 0\n",
        "    label_files = glob.glob(os.path.join(labels_dir, \"*.txt\"))\n",
        "\n",
        "    for i, label_file in enumerate(label_files):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processing file {i+1}/{len(label_files)}...\")\n",
        "\n",
        "        base_name = os.path.basename(label_file)\n",
        "        image_name = os.path.splitext(base_name)[0] + \".jpg\"  # Assuming .jpg extension\n",
        "\n",
        "        # Define output paths\n",
        "        bbox_output_file = os.path.join(bbox_labels_dir, base_name)\n",
        "        seg_output_file = os.path.join(seg_labels_dir, base_name)\n",
        "\n",
        "        # Split the label file\n",
        "        has_bbox, has_seg = split_label_file(label_file, bbox_output_file, seg_output_file)\n",
        "\n",
        "        # If the image exists, copy it to the appropriate dataset(s)\n",
        "        image_path = os.path.join(images_dir, image_name)\n",
        "        if os.path.exists(image_path):\n",
        "            if has_bbox:\n",
        "                shutil.copy(image_path, os.path.join(bbox_images_dir, image_name))\n",
        "                processed_bbox += 1\n",
        "            if has_seg:\n",
        "                shutil.copy(image_path, os.path.join(seg_images_dir, image_name))\n",
        "                processed_seg += 1\n",
        "\n",
        "    print(f\"✅ Processed {processed_bbox} images for bbox detection and {processed_seg} images for segmentation\")\n",
        "\n",
        "# Function to create YAML configuration files\n",
        "def create_yaml_file(dataset_path, nc, names):\n",
        "    \"\"\"Create a YAML configuration file for the dataset\"\"\"\n",
        "    yaml_content = {\n",
        "        'train': 'train/images',\n",
        "        'val': 'valid/images',\n",
        "        'test': 'test/images',\n",
        "        'nc': nc,\n",
        "        'names': names\n",
        "    }\n",
        "\n",
        "    yaml_path = os.path.join(dataset_path, 'data.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
        "\n",
        "    print(f\"✅ Created YAML configuration at: {yaml_path}\")\n",
        "\n",
        "# Function to run inference and combine results\n",
        "def run_inference_and_combine(bbox_model_path, seg_model_path, test_images_dir, output_dir):\n",
        "    \"\"\"Run inference with both models and combine results\"\"\"\n",
        "    # Load models\n",
        "    bbox_model = YOLO(bbox_model_path)\n",
        "    seg_model = YOLO(seg_model_path)\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get list of test images\n",
        "    image_paths = glob.glob(os.path.join(test_images_dir, \"*.jpg\"))\n",
        "\n",
        "    if not image_paths:\n",
        "        print(f\"⚠️ No images found in {test_images_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Running inference on {len(image_paths)} images...\")\n",
        "\n",
        "    # Run inference on all test images\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Processing image {i+1}/{len(image_paths)}...\")\n",
        "\n",
        "        image_name = os.path.basename(image_path)\n",
        "\n",
        "        # Load image\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(f\"⚠️ Failed to load image: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        # Run inference with both models\n",
        "        bbox_results = bbox_model.predict(img, save=False, verbose=False)\n",
        "        seg_results = seg_model.predict(img, save=False, verbose=False)\n",
        "\n",
        "        # Create a new image with combined results\n",
        "        result_img = img.copy()\n",
        "\n",
        "        # Process bounding box detections (Crack and Rust)\n",
        "        if bbox_results and len(bbox_results[0].boxes) > 0:\n",
        "            boxes = bbox_results[0].boxes\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                if conf > 0.25:  # Confidence threshold\n",
        "                    # Class 0 is Crack (red color)\n",
        "                    if cls == 0:\n",
        "                        color = (0, 0, 255)  # BGR format: red\n",
        "                        label = f\"Crack {conf:.2f}\"\n",
        "                    # Class 1 is Rust (blue color)\n",
        "                    else:\n",
        "                        color = (255, 0, 0)  # BGR format: blue\n",
        "                        label = f\"Rust {conf:.2f}\"\n",
        "\n",
        "                    # Draw bounding box\n",
        "                    cv2.rectangle(result_img, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "                    # Draw label\n",
        "                    cv2.putText(result_img, label, (x1, y1 - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Process segmentation detections (Tower Structure)\n",
        "        if seg_results and hasattr(seg_results[0], 'masks') and seg_results[0].masks is not None:\n",
        "            masks = seg_results[0].masks\n",
        "\n",
        "            # Create an overlay for the segmentation\n",
        "            overlay = result_img.copy()\n",
        "\n",
        "            for i, mask_tensor in enumerate(masks.data):\n",
        "                # Convert mask tensor to numpy array and resize to image dimensions\n",
        "                mask = mask_tensor.cpu().numpy()\n",
        "                mask = cv2.resize(mask, (result_img.shape[1], result_img.shape[0]))\n",
        "\n",
        "                # Apply the mask\n",
        "                overlay[mask > 0.5] = overlay[mask > 0.5] * 0.7 + np.array([0, 255, 0]) * 0.3\n",
        "\n",
        "            # Add the overlay to the result image\n",
        "            cv2.addWeighted(overlay, 0.7, result_img, 0.3, 0, result_img)\n",
        "\n",
        "            # Add label for Tower Structure\n",
        "            cv2.putText(result_img, \"Tower Structure\", (10, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Save the result image\n",
        "        output_path = os.path.join(output_dir, image_name)\n",
        "        cv2.imwrite(output_path, result_img)\n",
        "\n",
        "        # Display a sample result every 10 images\n",
        "        if i % 10 == 0:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            # Convert BGR to RGB for correct display\n",
        "            plt_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "            plt.imshow(plt_img)\n",
        "            plt.title(f\"Detection Results: {image_name}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    print(f\"✅ Inference completed. Results saved to: {output_dir}\")\n",
        "\n",
        "# Main function to prepare datasets\n",
        "def prepare_datasets():\n",
        "    \"\"\"Main function to prepare the datasets\"\"\"\n",
        "    # Create directory structure\n",
        "    create_directory_structure()\n",
        "\n",
        "    # Process each split\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        process_split(split)\n",
        "\n",
        "    # Create YAML files for both datasets\n",
        "    create_yaml_file(BBOX_DATASET, 2, [\"Crack\", \"Rust\"])\n",
        "    create_yaml_file(SEG_DATASET, 1, [\"Tower Structure\"])\n",
        "\n",
        "    print(\"\\n✅ Dataset preparation completed!\")\n",
        "    print(f\"📁 Bounding box dataset for YOLOv8m created at: {BBOX_DATASET}\")\n",
        "    print(f\"📁 Segmentation dataset for YOLOv8m-seg created at: {SEG_DATASET}\")\n",
        "\n",
        "# Run inference from trained models\n",
        "def run_inference():\n",
        "    \"\"\"Run inference using trained models\"\"\"\n",
        "    bbox_model_path = input(\"Enter path to trained bbox model (e.g., runs/detect/train/weights/best.pt): \")\n",
        "    seg_model_path = input(\"Enter path to trained segmentation model (e.g., runs/segment/train/weights/best.pt): \")\n",
        "    test_images_dir = input(f\"Enter path to test images directory (default: {DATASET_ROOT}/test/images): \") or f\"{DATASET_ROOT}/test/images\"\n",
        "    output_dir = input(f\"Enter path for output directory (default: {DATASET_ROOT}/combined_results): \") or f\"{DATASET_ROOT}/combined_results\"\n",
        "\n",
        "    if not os.path.exists(bbox_model_path):\n",
        "        print(f\"❌ Bbox model not found at {bbox_model_path}\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(seg_model_path):\n",
        "        print(f\"❌ Segmentation model not found at {seg_model_path}\")\n",
        "        return\n",
        "\n",
        "    run_inference_and_combine(bbox_model_path, seg_model_path, test_images_dir, output_dir)\n",
        "\n",
        "# Interactive menu for Colab\n",
        "def interactive_menu():\n",
        "    \"\"\"Display an interactive menu for the Colab notebook\"\"\"\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"🔍 YOLO Dataset Processor for Detection and Segmentation\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        print(\"1. Prepare Datasets (Split into bbox and segmentation)\")\n",
        "        print(\"2. Run Inference\")\n",
        "        print(\"3. Exit\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        choice = input(\"Enter your choice (1-5): \")\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        if choice == '1':\n",
        "            prepare_datasets()\n",
        "        elif choice == '2':\n",
        "            run_inference()\n",
        "        elif choice == '3':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interactive_menu()"
      ],
      "metadata": {
        "id": "Gcr2Vnjfl2CR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558870ea-5692-434d-940d-86dd83ae504d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q64IcjV8fam0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train \\\n",
        "  model=yolov8m.pt \\\n",
        "  data={BBOX_DATASET}/data.yaml \\\n",
        "  epochs=100 imgsz=1280 plots=True \\\n",
        "  patience=5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFDL8MNIlFeA",
        "outputId": "713048a3-2910-4bbd-b05b-94a7a60aeb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics 8.3.143 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 96.2±46.7 MB/s, size: 182.2 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/train/labels... 2516 images, 0 backgrounds, 0 corrupt: 100% 2516/2516 [00:26<00:00, 94.01it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/train/images/BA_Knights_HIll_FM_Mast_00372_jpg.rf.02f6ae65fdc662c734e47b224619cc39.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/train/images/BA_Knights_HIll_FM_Mast_00372_jpg.rf.fac4a21bffde7aeeddf916eb293b48d3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 832, len(boxes) = 49386. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.7±0.5 ms, read: 67.1±43.7 MB/s, size: 189.4 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/valid/labels... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:01<00:00, 148.43it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-8/bbox_dataset/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 40, len(boxes) = 2776. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      27.3G      2.489      2.676      1.997         71       1280: 100% 158/158 [01:02<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.32it/s]\n",
            "                   all        150       2776     0.0231     0.0639     0.0129    0.00431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      26.4G      2.447      2.523      1.969         77       1280: 100% 158/158 [01:00<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.42it/s]\n",
            "                   all        150       2776     0.0738      0.071     0.0351     0.0107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100        29G      2.411      2.471      1.948        130       1280: 100% 158/158 [00:59<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.37it/s]\n",
            "                   all        150       2776     0.0644     0.0755     0.0326     0.0113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100        29G      2.396      2.474      1.944         80       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.15it/s]\n",
            "                   all        150       2776     0.0845     0.0881     0.0478     0.0154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      25.1G      2.335      2.448       1.91        134       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.56it/s]\n",
            "                   all        150       2776      0.114     0.0697     0.0504     0.0181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      29.2G      2.322      2.417      1.895         46       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.32it/s]\n",
            "                   all        150       2776     0.0872     0.0764     0.0454      0.015\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100        27G      2.321      2.404      1.872         89       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.24it/s]\n",
            "                   all        150       2776      0.098     0.0829     0.0514     0.0181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      26.5G      2.283      2.355      1.851        102       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.45it/s]\n",
            "                   all        150       2776      0.105     0.0795     0.0515     0.0182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      27.6G      2.269      2.362      1.849         60       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.18it/s]\n",
            "                   all        150       2776     0.0925     0.0775       0.05     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      28.5G      2.263      2.326      1.828        106       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.45it/s]\n",
            "                   all        150       2776      0.608     0.0757     0.0543     0.0185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100      28.2G      2.258      2.337      1.827        143       1280: 100% 158/158 [00:59<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.54it/s]\n",
            "                   all        150       2776      0.113     0.0816     0.0554     0.0195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100      27.3G      2.237      2.329      1.825        119       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.65it/s]\n",
            "                   all        150       2776      0.615      0.082     0.0566     0.0196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100      27.1G      2.228      2.323      1.828        132       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.54it/s]\n",
            "                   all        150       2776      0.621     0.0782     0.0585     0.0204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100      28.6G      2.213      2.301      1.807        208       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.44it/s]\n",
            "                   all        150       2776      0.598     0.0932     0.0781     0.0278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100      26.7G      2.218      2.295       1.81         66       1280: 100% 158/158 [00:59<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.52it/s]\n",
            "                   all        150       2776       0.62     0.0854       0.21     0.0508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100      26.9G      2.188      2.265      1.794         64       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.52it/s]\n",
            "                   all        150       2776      0.608     0.0862     0.0573     0.0204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100      28.3G      2.191      2.256      1.799         97       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.62it/s]\n",
            "                   all        150       2776      0.117     0.0876     0.0578     0.0203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100      26.2G      2.188       2.25      1.781        134       1280: 100% 158/158 [00:59<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:02<00:00,  2.34it/s]\n",
            "                   all        150       2776      0.613     0.0854     0.0903     0.0262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100      25.5G      2.185      2.259      1.794         78       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.68it/s]\n",
            "                   all        150       2776      0.603     0.0865     0.0542     0.0193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100      27.9G      2.167      2.249      1.787         60       1280: 100% 158/158 [00:59<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:01<00:00,  2.61it/s]\n",
            "                   all        150       2776      0.615     0.0804      0.058     0.0209\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 15, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "20 epochs completed in 0.350 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 52.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 52.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.143 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:03<00:00,  1.61it/s]\n",
            "                   all        150       2776       0.62     0.0856      0.211     0.0509\n",
            "                 Crack         10         14          1          0      0.305     0.0611\n",
            "                  Rust        146       2762      0.241      0.171      0.116     0.0406\n",
            "Speed: 0.5ms preprocess, 5.8ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# For detection model (cracks and rust)\n",
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/runs/detect/train/weights/best.pt source=/content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images conf=0.25 save=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8xRtWbX739j",
        "outputId": "7692e353-46ba-44a8-97b6-ba747c92ad64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics 8.3.143 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\n",
            "image 1/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00009_jpg.rf.d802a6d89a68dc8dcede1b4153cd6068.jpg: 1280x1280 1 Rust, 11.7ms\n",
            "image 2/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00013_jpg.rf.01f74c95027c13bdc79ffc7abb552377.jpg: 1280x1280 5 Rusts, 11.7ms\n",
            "image 3/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00023_jpg.rf.3f7e9939df5c66836cdace84c4b94209.jpg: 1280x1280 3 Rusts, 11.7ms\n",
            "image 4/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00060_jpg.rf.ae51e3ae5905f610a1970e5378073652.jpg: 1280x1280 2 Rusts, 11.6ms\n",
            "image 5/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00069_jpg.rf.9c2e2eb1b60b88186ebb4b6ed5227b3b.jpg: 1280x1280 2 Rusts, 11.6ms\n",
            "image 6/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00074_jpg.rf.69c253efb06406a536c9f9a318eecc14.jpg: 1280x1280 10 Rusts, 11.6ms\n",
            "image 7/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00075_jpg.rf.d4d20832c76256711112ffc6b18eacd4.jpg: 1280x1280 5 Rusts, 11.6ms\n",
            "image 8/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00076_jpg.rf.845b6bb3057229e30202823e74c8668d.jpg: 1280x1280 2 Rusts, 11.6ms\n",
            "image 9/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00080_jpg.rf.a730f15d4f6361f010f69763a66306e9.jpg: 1280x1280 7 Rusts, 11.6ms\n",
            "image 10/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00092_jpg.rf.a61656bd6223d9dc6f50261fcc947789.jpg: 1280x1280 5 Rusts, 11.6ms\n",
            "image 11/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00098_jpg.rf.39ee231ee3f9140edc05e8bb9983e8f1.jpg: 1280x1280 6 Rusts, 11.7ms\n",
            "image 12/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00106_jpg.rf.d6763ab467d4827e6a0fa1c222ce2107.jpg: 1280x1280 3 Rusts, 11.7ms\n",
            "image 13/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00108_jpg.rf.3eb7248e176768fb1a3ef81ae3222de0.jpg: 1280x1280 9 Rusts, 11.6ms\n",
            "image 14/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00126_jpg.rf.2240fa357ef5c29f1146e133fabe11e8.jpg: 1280x1280 7 Rusts, 11.6ms\n",
            "image 15/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00127_jpg.rf.909730f5c16facd36243c238a0046582.jpg: 1280x1280 4 Rusts, 11.6ms\n",
            "image 16/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00178_jpg.rf.7db97de06fbdf7204e2f61a5612c0c85.jpg: 1280x1280 8 Rusts, 11.6ms\n",
            "image 17/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00199_jpg.rf.e36eb15ed514659822776f7a8c21aa1a.jpg: 1280x1280 7 Rusts, 11.6ms\n",
            "image 18/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00228_JPG.rf.6f15d2def43b58ef6d9db8b1088d99bb.jpg: 1280x1280 7 Rusts, 11.6ms\n",
            "image 19/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00291_JPG.rf.1217ed4ca52938962c87891c818d1ca2.jpg: 1280x1280 6 Rusts, 11.7ms\n",
            "image 20/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00345_jpg.rf.f999c72c12a83584d45845645b7bd6ae.jpg: 1280x1280 2 Rusts, 11.7ms\n",
            "image 21/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00348_jpg.rf.d93b5cc9bca68760e9ca144bfb821436.jpg: 1280x1280 6 Rusts, 11.7ms\n",
            "image 22/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00374_jpg.rf.f2cf2578f2afeac0678c58278802cc49.jpg: 1280x1280 7 Rusts, 11.7ms\n",
            "image 23/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00385_jpg.rf.c888968e6d777f4cde1866af1333e46e.jpg: 1280x1280 12 Rusts, 11.7ms\n",
            "image 24/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00395_jpg.rf.5f720b6afe4f7b073ea4781a31a86031.jpg: 1280x1280 14 Rusts, 11.7ms\n",
            "image 25/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00402_jpg.rf.499129a007f71f3042769345f57b89cd.jpg: 1280x1280 14 Rusts, 11.6ms\n",
            "image 26/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00413_jpg.rf.73a1b6b2534490e8c50df3d2be4834fd.jpg: 1280x1280 12 Rusts, 11.6ms\n",
            "image 27/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00419_jpg.rf.76f64ac406ccb8657520ca2d8ed03287.jpg: 1280x1280 6 Rusts, 11.7ms\n",
            "image 28/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00434_jpg.rf.bae1d8342259bb648dc814bc585dd25a.jpg: 1280x1280 12 Rusts, 11.7ms\n",
            "image 29/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00455_jpg.rf.b2c9a060db92b7d462ccef0590c94acf.jpg: 1280x1280 23 Rusts, 11.7ms\n",
            "image 30/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00457_jpg.rf.b5fa0f47b228bd56f765dc4258de4600.jpg: 1280x1280 11 Rusts, 11.7ms\n",
            "image 31/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00467_jpg.rf.a9f6eaefca54ae6a1b88c39b39db05f0.jpg: 1280x1280 7 Rusts, 11.7ms\n",
            "image 32/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00481_jpg.rf.e2f1f2856bd92afde5e47bf7bcacea89.jpg: 1280x1280 (no detections), 11.7ms\n",
            "image 33/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00485_jpg.rf.dc2721686da22715dac063e5d106b9f8.jpg: 1280x1280 (no detections), 11.7ms\n",
            "image 34/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00496_jpg.rf.542b602f6f867fab6aefbb9081bebe2f.jpg: 1280x1280 (no detections), 11.6ms\n",
            "image 35/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00522_JPG.rf.dab4a582a34ea6c2cc2aa7281c38b262.jpg: 1280x1280 9 Rusts, 11.6ms\n",
            "image 36/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00527_JPG.rf.56fe466ee2fce53677d611d987d9607d.jpg: 1280x1280 16 Rusts, 11.7ms\n",
            "image 37/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00532_JPG.rf.3e68bae5c56528b8694db92a92c94d96.jpg: 1280x1280 9 Rusts, 12.4ms\n",
            "image 38/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00549_JPG.rf.ec1f3bfbd7a5c8ede56605f0afb9edf1.jpg: 1280x1280 10 Rusts, 11.7ms\n",
            "image 39/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00561_JPG.rf.a6c8b2975e3ef49d732433a54e02751c.jpg: 1280x1280 20 Rusts, 11.6ms\n",
            "image 40/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00562_JPG.rf.6a97c1d15fe5ce7a5a8f7eb7a483c669.jpg: 1280x1280 21 Rusts, 11.6ms\n",
            "image 41/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00579_JPG.rf.38c7676263fec32fb7b9c6d0086c2591.jpg: 1280x1280 21 Rusts, 11.7ms\n",
            "image 42/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00580_JPG.rf.01a98bf27cf232ce1d60915bf7f0e1af.jpg: 1280x1280 18 Rusts, 11.7ms\n",
            "image 43/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00584_JPG.rf.cefe016ed619f8e8aa3779c09e3c871c.jpg: 1280x1280 20 Rusts, 11.6ms\n",
            "image 44/44 /content/drive/MyDrive/ColabNotebooks/COS40007/Final-Project/COS40007-Final-Project-7/test/images/BA_Knights_HIll_FM_Mast_00586_JPG.rf.d739abe706a7e41ebc1012f97b1317b6.jpg: 1280x1280 11 Rusts, 11.7ms\n",
            "Speed: 12.6ms preprocess, 11.7ms inference, 4.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    }
  ]
}